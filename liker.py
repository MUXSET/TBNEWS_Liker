# =================================================================
#  liker.py
#  Version: 1.0.0
#  Author: MUXSET (Refactored by Senior Software Engineer)
#  Description: è‡ªåŠ¨æ‰«æç‚¹èµä¸“å®¶æ¨¡å—ã€‚
#               ä» app_context è·å–æ ‡å‡†è·¯å¾„ï¼Œé€šè¿‡æ¥æ”¶Tokenå‚æ•°æ‰§è¡Œ
#               æ‰«æå’Œç‚¹èµï¼Œå®ç°äº†ä¸šåŠ¡é€»è¾‘çš„å®Œå…¨åˆ†ç¦»ã€‚
# =================================================================

import requests
import time
import json
import os
from app_context import PROGRESS_FILE_PATH

INITIAL_SCAN_START_ID = 8141
MAX_CONSECUTIVE_INVALID_ARTICLES = 15
ARTICLE_DETAIL_API_URL = "https://tbeanews.tbea.com/api/article/detail"
LIKE_API_URL = "https://tbeanews.tbea.com/api/article/addDigg"

def _load_progress() -> int:
    if os.path.exists(PROGRESS_FILE_PATH):
        try:
            with open(PROGRESS_FILE_PATH, "r", encoding="utf-8") as f:
                return int(json.load(f).get("last_liked_id", INITIAL_SCAN_START_ID - 1))
        except (json.JSONDecodeError, ValueError, OSError):
            pass
    return INITIAL_SCAN_START_ID - 1

def _save_progress(liked_id: int):
    with open(PROGRESS_FILE_PATH, "w", encoding="utf-8") as f:
        json.dump({"last_liked_id": liked_id}, f, indent=4)
    print(f"  ğŸ’¾ [ç‚¹èµæ¨¡å—] è¿›åº¦å·²ä¿å­˜: æœ€åä¸€ä¸ªæˆåŠŸç‚¹èµçš„IDæ˜¯ {liked_id}ã€‚")

def _perform_like(session: requests.Session, article_id: int, token: str) -> bool:
    headers = {"token": token, "User-Agent": "Mozilla/5.0"}
    try:
        response = session.post(LIKE_API_URL, headers=headers, json={"id": str(article_id)}, timeout=15)
        response.raise_for_status()
        data = response.json()
        if data.get("code") == 1 or "é‡å¤ç‚¹èµ" in data.get('msg', ''):
            print(f"  âœ… [ç‚¹èµæ¨¡å—] æ–‡ç« ID {article_id} ç‚¹èµæˆåŠŸ (æˆ–å·²ç‚¹èµ)ã€‚")
            return True
        else:
            print(f"  âŒ [ç‚¹èµæ¨¡å—] æ–‡ç« ID {article_id} ç‚¹èµå¤±è´¥: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"  âŒ [ç‚¹èµæ¨¡å—] ç‚¹èµæ–‡ç«  {article_id} æ—¶ç½‘ç»œé”™è¯¯: {e}")
        return False

def run_like_scan(token: str):
    if not token:
        print("  âŒ [ç‚¹èµæ¨¡å—] è‡´å‘½é”™è¯¯: æœªæä¾›æœ‰æ•ˆçš„Tokenã€‚")
        return

    session = requests.Session()
    last_liked_id = _load_progress()
    current_id = last_liked_id + 1
    consecutive_invalid_count = 0
    print(f"  â–¶ï¸  [ç‚¹èµæ¨¡å—] æ‰«æèµ·ç‚¹: ID {current_id}")

    while consecutive_invalid_count < MAX_CONSECUTIVE_INVALID_ARTICLES:
        try:
            response = session.get(ARTICLE_DETAIL_API_URL, params={'id': current_id}, headers={"token": token}, timeout=10)
            response.raise_for_status()
            data = response.json()

            if data.get('code') == 1 and data.get('data'):
                consecutive_invalid_count = 0
                if _perform_like(session, current_id, token):
                    _save_progress(current_id)
                else:
                    print("  â†³ å…³é”®æ“ä½œ(ç‚¹èµ)å¤±è´¥ï¼Œä¸­æ­¢æœ¬è½®ä»»åŠ¡ä»¥ä¾¿ä¸‹æ¬¡é‡è¯•ã€‚")
                    break
            else:
                consecutive_invalid_count += 1
                print(f"  - [ç‚¹èµæ¨¡å—] æ— æ•ˆID {current_id} (è¿ç»­ {consecutive_invalid_count}/{MAX_CONSECUTIVE_INVALID_ARTICLES})")

        except requests.exceptions.RequestException as e:
            print(f"  â†³ æ£€æŸ¥ID {current_id} æ—¶å‘ç”Ÿç½‘ç»œé”™è¯¯: {e}ã€‚ä¸­æ­¢ä»»åŠ¡ã€‚")
            break

        current_id += 1
        time.sleep(0.5)

    if consecutive_invalid_count >= MAX_CONSECUTIVE_INVALID_ARTICLES:
        print(f"\n  ğŸ [ç‚¹èµæ¨¡å—] å·²è¿ç»­å‘ç° {MAX_CONSECUTIVE_INVALID_ARTICLES} ä¸ªæ— æ•ˆIDï¼Œæœ¬è½®æ‰«ææ­£å¸¸ç»“æŸã€‚")
